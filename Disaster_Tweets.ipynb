{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2dd0304",
   "metadata": {},
   "source": [
    "### Natural Language Processing with Disaster Tweets\n",
    "This project will determent the semantic of a sentence by deep neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "436458be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from torch.utils.data import DataLoader\n",
    "import transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn import model_selection, metrics\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f50fb67",
   "metadata": {},
   "source": [
    "### Data Inspection\n",
    "let's look at our data before we do the processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3873826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id keyword location                                               text  \\\n",
      "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
      "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
      "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
      "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
      "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
      "\n",
      "   target  \n",
      "0       1  \n",
      "1       1  \n",
      "2       1  \n",
      "3       1  \n",
      "4       1  \n",
      "   id keyword location                                               text\n",
      "0   0     NaN      NaN                 Just happened a terrible car crash\n",
      "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
      "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
      "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
      "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "print(train.head(5))\n",
    "print(test.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cfc18c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n",
      "None\n",
      "There are 2 classes of target\n"
     ]
    }
   ],
   "source": [
    "n_classes = len(sorted(list(set(train['target']))))\n",
    "print(train.info())\n",
    "print(f'There are {n_classes} classes of target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c361b235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3263 entries, 0 to 3262\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        3263 non-null   int64 \n",
      " 1   keyword   3237 non-null   object\n",
      " 2   location  2158 non-null   object\n",
      " 3   text      3263 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 102.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf182acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword has 61 NaN, 222 unique value\n",
      "location has 2533 NaN, 3342 unique value\n"
     ]
    }
   ],
   "source": [
    "for i in ['keyword', 'location']:\n",
    "    print(f'{i} has {train[i].isna().sum()} NaN, {len(train[i].unique())} unique value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d29c6207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4342\n",
      "1    3271\n",
      "Name: target, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = train['target'].value_counts()\n",
    "plt.bar([0,1],t.values,width=0.5)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "533e6271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average words for training text is 13.928937344016813\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAANvklEQVR4nO3dX4hc93nG8e9TOXVN/lC7lo2R1K5bdBHbNAoRrsG9cJISq3GonAuDAm10EVAxDiSQUuTcpC0I3IumJVAb1MZYoUmMIHEt6qaNUFPcQoizTt3K8h8sYtVWJSylocS5cbHz9mKO6LAeaVe7q9nVvN8PDOecd86Z83sRfnz4zZmzqSokST383FoPQJI0PYa+JDVi6EtSI4a+JDVi6EtSI1es9QAWc+2119bc3NxaD0OSLitPP/30j6pq48L6ug/9ubk55ufn13oYknRZSfKfk+pO70hSI4a+JDVi6EtSI4a+JDVi6EtSI4a+JDVi6EtSI4a+JDVi6EtSI+v+F7m6PMztfWLNzn3igbvW7NzS5cYrfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxOfpz5i1fK69pPXPK31JasTQl6RGDH1JasTQl6RGDH1JasTQl6RGDH1JasTQl6RGDH1JasTQl6RGDH1JamTR0E+yJcl3kjyf5FiSzwz1a5IcTvLSsLx67Jj7kxxP8mKSO8fqH0hydHjvS0lyadqSJE2ylCv9N4HPVdV7gduA+5LcBOwFjlTVVuDIsM3w3i7gZmAH8GCSDcNnPQTsAbYOrx2r2IskaRGLhn5Vna6qHwzrrwPPA5uAncCBYbcDwN3D+k7g0ap6o6peBo4Dtya5AXhPVX23qgr4ytgxkqQpuKg5/SRzwPuB7wHXV9VpGP2PAbhu2G0T8OrYYSeH2qZhfWF90nn2JJlPMn/27NmLGaIk6QKWHPpJ3gV8A/hsVf3kQrtOqNUF6m8vVu2vqu1VtX3jxo1LHaIkaRFLCv0k72AU+F+tqm8O5deGKRuG5ZmhfhLYMnb4ZuDUUN88oS5JmpKl3L0T4MvA81X1xbG3DgG7h/XdwONj9V1JrkxyI6MvbJ8apoBeT3Lb8JmfHDtGkjQFS/lzibcDvwccTfLMUPs88ABwMMmngFeAewCq6liSg8BzjO78ua+q3hqOuxd4BLgK+NbwkiRNyaKhX1X/yuT5eIAPn+eYfcC+CfV54JaLGaAkafX4i1xJasTQl6RGDH1JasTQl6RGDH1JasTQl6RGDH1JasTQl6RGDH1JasTQl6RGDH1JasTQl6RGDH1JasTQl6RGDH1JasTQl6RGDH1JasTQl6RGDH1JamQpfxhdF2lu7xNrPQRJmsgrfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqZNHQT/JwkjNJnh2r/VGS/0ryzPD66Nh79yc5nuTFJHeO1T+Q5Ojw3peSZPXbkSRdyFKu9B8Bdkyo/3lVbRtefw+Q5CZgF3DzcMyDSTYM+z8E7AG2Dq9JnylJuoQWDf2qehL48RI/byfwaFW9UVUvA8eBW5PcALynqr5bVQV8Bbh7mWOWJC3TSub0P53kP4bpn6uH2ibg1bF9Tg61TcP6wvpESfYkmU8yf/bs2RUMUZI0brmh/xDwa8A24DTwZ0N90jx9XaA+UVXtr6rtVbV948aNyxyiJGmhZYV+Vb1WVW9V1c+AvwJuHd46CWwZ23UzcGqob55QlyRN0bJCf5ijP+fjwLk7ew4Bu5JcmeRGRl/YPlVVp4HXk9w23LXzSeDxFYxbkrQMVyy2Q5KvA3cA1yY5CXwBuCPJNkZTNCeA3weoqmNJDgLPAW8C91XVW8NH3cvoTqCrgG8NL0nSFC0a+lX1iQnlL19g/33Avgn1eeCWixqdJGlV+YtcSWrE0JekRgx9SWrE0JekRgx9SWrE0JekRgx9SWrE0JekRgx9SWrE0JekRgx9SWrE0JekRgx9SWrE0JekRgx9SWrE0JekRgx9SWrE0JekRgx9SWrE0JekRgx9SWrE0JekRgx9SWrE0JekRgx9SWrE0JekRgx9SWrE0JekRgx9SWrE0JekRgx9SWrE0JekRgx9SWrE0JekRgx9SWpk0dBP8nCSM0meHatdk+RwkpeG5dVj792f5HiSF5PcOVb/QJKjw3tfSpLVb0eSdCFLudJ/BNixoLYXOFJVW4EjwzZJbgJ2ATcPxzyYZMNwzEPAHmDr8Fr4mZKkS2zR0K+qJ4EfLyjvBA4M6weAu8fqj1bVG1X1MnAcuDXJDcB7quq7VVXAV8aOkSRNyXLn9K+vqtMAw/K6ob4JeHVsv5NDbdOwvrA+UZI9SeaTzJ89e3aZQ5QkLbTaX+ROmqevC9Qnqqr9VbW9qrZv3Lhx1QYnSd0tN/RfG6ZsGJZnhvpJYMvYfpuBU0N984S6JGmKlhv6h4Ddw/pu4PGx+q4kVya5kdEXtk8NU0CvJ7ltuGvnk2PHSJKm5IrFdkjydeAO4NokJ4EvAA8AB5N8CngFuAegqo4lOQg8B7wJ3FdVbw0fdS+jO4GuAr41vCRJU7Ro6FfVJ87z1ofPs/8+YN+E+jxwy0WNTpK0qvxFriQ1YuhLUiOGviQ1YuhLUiOGviQ1YuhLUiOGviQ1YuhLUiOGviQ1YuhLUiOGviQ1YuhLUiOGviQ1YuhLUiOGviQ1YuhLUiOGviQ1YuhLUiOGviQ1sujfyJXWu7m9T6zJeU88cNeanFdaCa/0JakRQ1+SGjH0JakRQ1+SGjH0JakRQ1+SGjH0JakRQ1+SGjH0JakRQ1+SGjH0JamRmX72zlo9k0WS1iuv9CWpEUNfkhox9CWpkRWFfpITSY4meSbJ/FC7JsnhJC8Ny6vH9r8/yfEkLya5c6WDlyRdnNW40v9gVW2rqu3D9l7gSFVtBY4M2yS5CdgF3AzsAB5MsmEVzi9JWqJLMb2zEzgwrB8A7h6rP1pVb1TVy8Bx4NZLcH5J0nmsNPQL+HaSp5PsGWrXV9VpgGF53VDfBLw6duzJofY2SfYkmU8yf/bs2RUOUZJ0zkrv07+9qk4luQ44nOSFC+ybCbWatGNV7Qf2A2zfvn3iPpKki7eiK/2qOjUszwCPMZqueS3JDQDD8syw+0lgy9jhm4FTKzm/JOniLDv0k7wzybvPrQMfAZ4FDgG7h912A48P64eAXUmuTHIjsBV4arnnlyRdvJVM71wPPJbk3Od8rar+Icn3gYNJPgW8AtwDUFXHkhwEngPeBO6rqrdWNHpJ0kVZduhX1Q+B902o/zfw4fMcsw/Yt9xzSpJWxl/kSlIjhr4kNWLoS1Ijhr4kNWLoS1Ijhr4kNWLoS1Ijhr4kNWLoS1Ijhr4kNWLoS1Ijhr4kNWLoS1Ijhr4kNWLoS1Ijhr4kNWLoS1Ijhr4kNWLoS1Ijhr4kNWLoS1Ijhr4kNWLoS1Ijhr4kNWLoS1Ijhr4kNWLoS1Ijhr4kNWLoS1Ijhr4kNWLoS1Ijhr4kNXLFWg9AulzN7X1izc594oG71uzcurx5pS9JjRj6ktTI1EM/yY4kLyY5nmTvtM8vSZ1NNfSTbAD+Evht4CbgE0lumuYYJKmzaV/p3wocr6ofVtX/Ao8CO6c8Bklqa9p372wCXh3bPgn8xsKdkuwB9gybP03y4jLPdy3wo2Uee7no0CP06HPJPeZPL/FILi3/LafjVyYVpx36mVCrtxWq9gP7V3yyZL6qtq/0c9azDj1Cjz479Ag9+lzPPU57eucksGVsezNwaspjkKS2ph363we2Jrkxyc8Du4BDUx6DJLU11emdqnozyaeBfwQ2AA9X1bFLeMoVTxFdBjr0CD367NAj9Ohz3faYqrdNqUuSZpS/yJWkRgx9SWpkJkN/Vh/1kOThJGeSPDtWuybJ4SQvDcur13KMK5VkS5LvJHk+ybEknxnqs9bnLyR5Ksm/D33+8VCfqT5h9Ev8JP+W5O+G7ZnqMcmJJEeTPJNkfqit2x5nLvRn/FEPjwA7FtT2AkeqaitwZNi+nL0JfK6q3gvcBtw3/PvNWp9vAB+qqvcB24AdSW5j9voE+Azw/Nj2LPb4waraNnZv/rrtceZCnxl+1ENVPQn8eEF5J3BgWD8A3D3NMa22qjpdVT8Y1l9nFBabmL0+q6p+Omy+Y3gVM9Znks3AXcBfj5VnqsfzWLc9zmLoT3rUw6Y1Gss0XF9Vp2EUmMB1azyeVZNkDng/8D1msM9h2uMZ4AxwuKpmsc+/AP4Q+NlYbdZ6LODbSZ4eHiED67jHWfzLWUt61IPWtyTvAr4BfLaqfpJM+me9vFXVW8C2JL8IPJbkljUe0qpK8jHgTFU9neSONR7OpXR7VZ1Kch1wOMkLaz2gC5nFK/1uj3p4LckNAMPyzBqPZ8WSvINR4H+1qr45lGeuz3Oq6n+Af2b0fc0s9Xk78DtJTjCaZv1Qkr9htnqkqk4NyzPAY4ymmNdtj7MY+t0e9XAI2D2s7wYeX8OxrFhGl/RfBp6vqi+OvTVrfW4crvBJchXwW8ALzFCfVXV/VW2uqjlG/x3+U1X9LjPUY5J3Jnn3uXXgI8CzrOMeZ/IXuUk+ymgu8dyjHvat7YhWR5KvA3cwemzra8AXgL8FDgK/DLwC3FNVC7/svWwk+U3gX4Cj/P888OcZzevPUp+/zugLvg2MLr4OVtWfJPklZqjPc4bpnT+oqo/NUo9JfpXR1T2Mpsu/VlX71nOPMxn6kqTJZnF6R5J0Hoa+JDVi6EtSI4a+JDVi6EtSI4a+JDVi6EtSI/8H3wK1mQo+at4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words_for_test = []\n",
    "for i in train['text']:\n",
    "    words_for_test.append(i.count(\" \"))\n",
    "plt.hist(words_for_test)\n",
    "print(f'Average words for training text is {np.average(words_for_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c0c89cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 keywords are {'fatalities': 45, 'deluge': 42, 'armageddon': 42, 'sinking': 41, 'damage': 41}\n",
      "The top 5 location are {'USA': 104, 'New York': 71, 'United States': 50, 'London': 45, 'Canada': 29}\n"
     ]
    }
   ],
   "source": [
    "key_counts = train['keyword'].value_counts()\n",
    "location_counts = train['location'].value_counts()\n",
    "\n",
    "key_top_five = dict(sorted(key_counts.items(), key = lambda x: x[1], reverse = True)[:5])\n",
    "location_top_five = dict(sorted(location_counts.items(), key = lambda x: x[1], reverse = True)[:5])\n",
    "print(f'The top 5 keywords are {str(key_top_five)}')\n",
    "print(f'The top 5 location are {str(location_top_five)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3356e0",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "We will write a function for dataset, which will be using for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "888dcc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, text, target, tokenizer, max_len):\n",
    "        self.text = text\n",
    "        self.target = target\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        text = \" \".join(str(self.text[item]).split())\n",
    "        inputs = tokenizer.encode_plus(text, None, add_special_tokens = True, max_length = self.max_len)\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        \n",
    "        padding_len = self.max_len - len(ids)\n",
    "        ids = ids + ([0] * padding_len)\n",
    "        mask = mask + ([0] * padding_len)\n",
    "        token_type_ids = token_type_ids + ([0] * padding_len)\n",
    "        \n",
    "        return {\n",
    "            \"ids\": torch.tensor(ids, dtype = torch.long),\n",
    "            \"mask\": torch.tensor(mask, dtype = torch.long),\n",
    "            \"token_type_ids\": torch.tensor(token_type_ids, dtype = torch.long),\n",
    "            \"targets\": torch.tensor(self.target[item], dtype = torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f74ff3",
   "metadata": {},
   "source": [
    "### Setup model\n",
    "Now, we will setup our model. Here, we will use transformer. Although we only learn LSTM and GUN, transformer is way better than traditional RNN, we will use the transformer library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fdb6f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will initialize the model\n",
    "class BERTBaseUncased(nn.Module):\n",
    "    def __init__(self, bert_path):\n",
    "        super(BERTBaseUncased, self).__init__()\n",
    "        self.bert = transformers.BertModel.from_pretrained(bert_path)\n",
    "        self.bert_drop = nn.Dropout(0.3)\n",
    "        self.out = nn.Linear(768, 1)\n",
    "        \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        _, o2 = self.bert(\n",
    "            ids,\n",
    "            attention_mask = mask,\n",
    "            token_type_ids = token_type_ids, \n",
    "            return_dict = False\n",
    "        )\n",
    "        bo = self.bert_drop(o2)\n",
    "        output = self.out(bo)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04c9a05",
   "metadata": {},
   "source": [
    "Setup our hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6061c242",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_MODEL = \"bert-base-uncased\"\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained(BERT_MODEL, do_lower_case=True)\n",
    "BATCH_SIZE = 8\n",
    "MAX_LEN = 128\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81cf70e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will drop other column beside the 'text'\n",
    "train = train.drop(['keyword','location'], axis=1)\n",
    "test = test.drop(['keyword','location'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0f6517",
   "metadata": {},
   "source": [
    "Casting our dataset for bert dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e35fa681",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = model_selection.train_test_split(train, test_size = 0.2, random_state = 4, stratify = train.target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9474c159",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(text = train_data.text.values, target = train_data.target.values, tokenizer = tokenizer, max_len = MAX_LEN)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = BATCH_SIZE)\n",
    "valid_dataset = Dataset(text = valid_data.text.values, target = valid_data.target.values, tokenizer = tokenizer, max_len = MAX_LEN)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "068f470e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERTBaseUncased(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (bert_drop): Dropout(p=0.3, inplace=False)\n",
       "  (out): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = BERTBaseUncased(BERT_MODEL)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd98a79",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Because the project is a binary problem, we will use simple BCE as our evaluation loss. In this part we will evaluate different model and try the cross validation, we will find the best model for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95dc770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_function(data_loader, model, optimizer, device, scheduler):\n",
    "    model.train()\n",
    "    for _, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "        ids = d[\"ids\"].to(device, dtype=torch.long)\n",
    "        mask = d[\"mask\"].to(device, dtype=torch.long)\n",
    "        token_type_ids = d[\"token_type_ids\"].to(device, dtype=torch.long)\n",
    "        targets = d[\"targets\"].to(device, dtype=torch.float)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "990a8980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_function(data_loader, model, device):\n",
    "    model.eval()\n",
    "    fin_outputs = []\n",
    "    fin_targets = []\n",
    "    with torch.no_grad():\n",
    "        for _, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "            ids = d[\"ids\"].to(device, dtype=torch.long)\n",
    "            mask = d[\"mask\"].to(device, dtype=torch.long)\n",
    "            token_type_ids = d[\"token_type_ids\"].to(device, dtype=torch.long)\n",
    "            targets = d[\"targets\"].to(device, dtype=torch.float)\n",
    "\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "    return np.vstack(fin_outputs), np.vstack(fin_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c517348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(predict, truth):\n",
    "    return nn.BCEWithLogitsLoss()(predict, truth.view(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b40d18",
   "metadata": {},
   "source": [
    "### Train and Test\n",
    "After we get decide the model, we will train this model with all our training set, and predice the test input. We will get our final score on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d7b37a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-4, weight_decay = 1e-3)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4c01141",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28df4d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 762/762 [02:03<00:00,  6.16it/s]\n",
      "100%|██████████| 191/191 [00:09<00:00, 19.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score = 0.8115561391989494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 762/762 [02:07<00:00,  6.00it/s]\n",
      "100%|██████████| 191/191 [00:09<00:00, 19.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score = 0.7944845699277742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 762/762 [02:08<00:00,  5.94it/s]\n",
      "100%|██████████| 191/191 [00:09<00:00, 19.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score = 0.804333552199606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 762/762 [02:18<00:00,  5.51it/s]\n",
      "100%|██████████| 191/191 [00:13<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score = 0.8056467498358503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 762/762 [02:10<00:00,  5.85it/s]\n",
      "100%|██████████| 191/191 [00:10<00:00, 18.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score = 0.7957977675640184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 762/762 [02:09<00:00,  5.91it/s]\n",
      "100%|██████████| 191/191 [00:10<00:00, 18.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score = 0.7380170715692712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 762/762 [02:14<00:00,  5.66it/s]\n",
      "100%|██████████| 191/191 [00:10<00:00, 17.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score = 0.7944845699277742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 762/762 [02:15<00:00,  5.62it/s]\n",
      "100%|██████████| 191/191 [00:10<00:00, 18.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score = 0.7905449770190414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 762/762 [02:12<00:00,  5.75it/s]\n",
      "100%|██████████| 191/191 [00:10<00:00, 18.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score = 0.7445830597504924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 762/762 [02:19<00:00,  5.46it/s]\n",
      "100%|██████████| 191/191 [00:10<00:00, 19.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score = 0.7787261982928431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    train_function(train_loader, model, optimizer, device, scheduler)\n",
    "    prediction, truth = eval_function(valid_loader, model, device)\n",
    "    \n",
    "    prediction = np.array(prediction) >= 0.5\n",
    "    accuracy = metrics.accuracy_score(truth, prediction)\n",
    "    print(f\"Epoch {epoch}: Accuracy score = {accuracy}\")\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a336fb",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "Now, we will train the model with all the training data, and predict the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310bde61",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_data = Dataset(text = train.text.values, target = train.target.values, tokenizer = tokenizer, max_len = MAX_LEN)\n",
    "train_loader = torch.utils.data.DataLoader(train_all_data, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17439ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model_final = BERTBaseUncased(BERT_MODEL)\n",
    "model_final.to(device)\n",
    "model = nn.DataParallel(model)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-4, weight_decay = 1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=10)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_function(train_loader, model, optimizer, device, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1c87a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3263/3263 [00:41<00:00, 78.69it/s]\n"
     ]
    }
   ],
   "source": [
    "test['target'] = [0]*len(test)\n",
    "test_data = Dataset(text = test.text.values, target = test.target.values, tokenizer = tokenizer, max_len = MAX_LEN)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = 1)\n",
    "\n",
    "prediction, _ = eval_function(test_loader, model, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7fdddccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  target\n",
      "0   0       1\n",
      "1   2       1\n",
      "2   3       1\n",
      "3   9       1\n",
      "4  11       1\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] = test['id']\n",
    "prediction = np.array(prediction) >= 0.5\n",
    "submission['target'] = prediction.astype(int)\n",
    "print(submission.head())\n",
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86d9205",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "This model have a not bad result, around 0.78 accuracy. We may improve the score by using a better model. Also, our training set is small, we can resample the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b135fc91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
